{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import idx2numpy\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = idx2numpy.convert_from_file('../t10k-images.idx3-ubyte')\n",
    "test_labels = idx2numpy.convert_from_file('../t10k-labels.idx1-ubyte')\n",
    "train_images = idx2numpy.convert_from_file('../train-images.idx3-ubyte')\n",
    "train_labels = idx2numpy.convert_from_file('../train-labels.idx1-ubyte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28)\n",
      "(10000,)\n",
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(test_images.shape)\n",
    "print(test_labels.shape)\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_flat=train_images.reshape(train_images.shape[0], -1).T\n",
    "test_images_flat=test_images.reshape(test_images.shape[0], -1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 60000)\n",
      "(784, 10000)\n",
      "Train Examples=60000\n",
      "Test Examples=10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(784, 60000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_images_flat.shape)\n",
    "print(test_images_flat.shape)\n",
    "m = train_images_flat.shape[1]\n",
    "m_test = test_images_flat.shape[1]\n",
    "print(f\"Train Examples={m}\")\n",
    "print(f\"Test Examples={m_test}\")\n",
    "X = train_images_flat/255\n",
    "X_test = test_images_flat/255\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y = train_labels.reshape(train_labels.shape[0],1).T # Y.shape is (1, m)\n",
    "# Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(row_vector, no_classes):\n",
    "    one_hot_vector = np.eye(no_classes)[row_vector.reshape(-1)]\n",
    "    return one_hot_vector.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Classes=10\n",
      "(10, 60000)\n",
      "(10, 10000)\n"
     ]
    }
   ],
   "source": [
    "C = train_labels.max()+1\n",
    "print(f\"No. of Classes={C}\")\n",
    "Y_hot = one_hot(train_labels,no_classes=C)\n",
    "Y_test_hot = one_hot(test_labels,no_classes=C)\n",
    "print(Y_hot.shape) #Y_hot.shape is (C,m)\n",
    "print(Y_test_hot.shape) #Y_hot.shape is (C,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(n_x,C):\n",
    "#     global W,b\n",
    "    W = np.random.randn(train_images_flat.shape[0], C)*0.001 # W.shape is (n_x,1)\n",
    "    b = 0 #np.zeros((1,m)) #b.shape is (1,m)\n",
    "    return W,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(W.shape)\n",
    "# print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    t = np.exp(z)\n",
    "    a = t / np.sum(t, keepdims=True, axis=0)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(W, X, b):\n",
    "#     global Z,A\n",
    "    Z = np.dot(W.T, X) + b # Z.shape is (C,m)\n",
    "    A = softmax(Z)  # A.shape is (C,m)\n",
    "    return Z, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(A, Y_hot):\n",
    "#     global L,J\n",
    "# Calculate Loss\n",
    "    L = -np.sum(Y_hot*np.log(A), keepdims=True, axis=0) # L.shape is (1,m)   \n",
    "    #calculate Cost\n",
    "    J = np.sum(L, keepdims=True, axis=1)*(1/m) # J.shape is (1,1) \n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deivatives\n",
    "def backward(X, Y_hot, A):\n",
    "#     global dZ, dW, db\n",
    "    #dJ/dZ\n",
    "    dZ = A-Y_hot  # dZ.shape is (C,m)   '''BROADCASTING GOING ON HERE'''\n",
    "\n",
    "    #dJ/dW = sum(dL/dW)/m  which is equivalent to np.dot(X,dZ.T)/m\n",
    "    '''\n",
    "    dLdW = X*dZ  # dLdW.shape is (n_x, m)\n",
    "    dW = np.sum(dLdW, keepdims=True, axis=1)/m  #dW.shape is (n_x,1) [same as W.shape]\n",
    "    '''\n",
    "    dW = np.dot(X, dZ.T) / m\n",
    "    #dJ/db\n",
    "    db = np.sum(dZ, keepdims=True, axis=1)/m  # db.shape = (1,1)\n",
    "    \n",
    "    return dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward()\n",
    "# cost()\n",
    "# backward()\n",
    "# A.shape, Y_hot.shape, L.shape, J.shape,Z.shape, dZ.shape, W.shape, dW.shape, db.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#optimise\n",
    "def optimize(W, X, b, Y_hot, alpha, iterations):\n",
    "#     global costs\n",
    "    costs=[]\n",
    "    for i in range(iterations):\n",
    "        Z, A = forward(W, X, b)\n",
    "        if i%5 ==0:\n",
    "            J = cost(A, Y_hot)\n",
    "            costs.append(J)\n",
    "            print(f'Cost at {i}th loop = {J}')\n",
    "        dW, db = backward(X, Y_hot, A)\n",
    "        W = W - alpha*dW\n",
    "        b = b - alpha*db\n",
    "    return W, b, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y_hot, C, alpha, iterations):\n",
    "    W, b = initialize(X.shape[1], C)\n",
    "    res_W, res_b, costs = optimize(W, X, b, Y_hot, alpha, iterations)\n",
    "    plt.plot(np.arange(0,iterations,5), np.array(costs).reshape(len(costs),1))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations')\n",
    "    plt.show()\n",
    "    return res_W, res_b, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_test, Y_test_hot, res_W, res_b):\n",
    "    Z_test, A_test = forward(res_W, X_test, res_b)\n",
    "    J_test = cost(A_test, Y_test_hot)\n",
    "    O_test = (np.max(A_test,axis=0) == A_test).T * np.array([0,1,2,3,4,5,6,7,8,9]).T\n",
    "    predicted_labels = np.sum(O_test,axis=1)\n",
    "    print(f'Accuracy : {100 - np.mean(np.abs(A_test - Y_test_hot))*100}')\n",
    "    print(f'Cost : {J_test}')\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at 0th loop = [[2.30235766]]\n",
      "Cost at 5th loop = [[2.25453622]]\n",
      "Cost at 10th loop = [[2.20864766]]\n",
      "Cost at 15th loop = [[2.16449201]]\n",
      "Cost at 20th loop = [[2.12192552]]\n",
      "Cost at 25th loop = [[2.08084167]]\n",
      "Cost at 30th loop = [[2.04115861]]\n",
      "Cost at 35th loop = [[2.00281083]]\n",
      "Cost at 40th loop = [[1.96574358]]\n",
      "Cost at 45th loop = [[1.92990919]]\n",
      "Cost at 50th loop = [[1.89526466]]\n",
      "Cost at 55th loop = [[1.86177006]]\n",
      "Cost at 60th loop = [[1.82938754]]\n",
      "Cost at 65th loop = [[1.79808071]]\n",
      "Cost at 70th loop = [[1.76781421]]\n",
      "Cost at 75th loop = [[1.73855353]]\n",
      "Cost at 80th loop = [[1.7102649]]\n",
      "Cost at 85th loop = [[1.68291518]]\n",
      "Cost at 90th loop = [[1.65647192]]\n",
      "Cost at 95th loop = [[1.63090331]]\n",
      "Cost at 100th loop = [[1.60617824]]\n",
      "Cost at 105th loop = [[1.58226629]]\n",
      "Cost at 110th loop = [[1.5591378]]\n",
      "Cost at 115th loop = [[1.53676388]]\n",
      "Cost at 120th loop = [[1.51511644]]\n",
      "Cost at 125th loop = [[1.49416817]]\n",
      "Cost at 130th loop = [[1.47389262]]\n",
      "Cost at 135th loop = [[1.45426416]]\n",
      "Cost at 140th loop = [[1.43525802]]\n",
      "Cost at 145th loop = [[1.41685026]]\n",
      "Cost at 150th loop = [[1.39901779]]\n",
      "Cost at 155th loop = [[1.38173836]]\n",
      "Cost at 160th loop = [[1.36499053]]\n",
      "Cost at 165th loop = [[1.34875368]]\n",
      "Cost at 170th loop = [[1.333008]]\n",
      "Cost at 175th loop = [[1.31773445]]\n",
      "Cost at 180th loop = [[1.30291474]]\n",
      "Cost at 185th loop = [[1.28853135]]\n",
      "Cost at 190th loop = [[1.27456745]]\n",
      "Cost at 195th loop = [[1.26100691]]\n",
      "Cost at 200th loop = [[1.24783429]]\n",
      "Cost at 205th loop = [[1.23503479]]\n",
      "Cost at 210th loop = [[1.22259422]]\n",
      "Cost at 215th loop = [[1.21049903]]\n",
      "Cost at 220th loop = [[1.1987362]]\n",
      "Cost at 225th loop = [[1.1872933]]\n",
      "Cost at 230th loop = [[1.17615843]]\n",
      "Cost at 235th loop = [[1.16532019]]\n",
      "Cost at 240th loop = [[1.15476768]]\n",
      "Cost at 245th loop = [[1.14449045]]\n",
      "Cost at 250th loop = [[1.13447852]]\n",
      "Cost at 255th loop = [[1.12472232]]\n",
      "Cost at 260th loop = [[1.1152127]]\n",
      "Cost at 265th loop = [[1.1059409]]\n",
      "Cost at 270th loop = [[1.09689853]]\n",
      "Cost at 275th loop = [[1.08807755]]\n",
      "Cost at 280th loop = [[1.07947026]]\n",
      "Cost at 285th loop = [[1.0710693]]\n",
      "Cost at 290th loop = [[1.0628676]]\n",
      "Cost at 295th loop = [[1.05485841]]\n",
      "Cost at 300th loop = [[1.04703522]]\n",
      "Cost at 305th loop = [[1.03939184]]\n",
      "Cost at 310th loop = [[1.03192228]]\n",
      "Cost at 315th loop = [[1.02462085]]\n",
      "Cost at 320th loop = [[1.01748205]]\n",
      "Cost at 325th loop = [[1.01050062]]\n",
      "Cost at 330th loop = [[1.00367151]]\n",
      "Cost at 335th loop = [[0.99698988]]\n",
      "Cost at 340th loop = [[0.99045107]]\n",
      "Cost at 345th loop = [[0.98405061]]\n",
      "Cost at 350th loop = [[0.9777842]]\n",
      "Cost at 355th loop = [[0.97164772]]\n",
      "Cost at 360th loop = [[0.9656372]]\n",
      "Cost at 365th loop = [[0.95974883]]\n",
      "Cost at 370th loop = [[0.95397894]]\n",
      "Cost at 375th loop = [[0.948324]]\n",
      "Cost at 380th loop = [[0.94278062]]\n",
      "Cost at 385th loop = [[0.93734553]]\n",
      "Cost at 390th loop = [[0.93201559]]\n",
      "Cost at 395th loop = [[0.92678776]]\n",
      "Cost at 400th loop = [[0.92165914]]\n",
      "Cost at 405th loop = [[0.9166269]]\n",
      "Cost at 410th loop = [[0.91168835]]\n",
      "Cost at 415th loop = [[0.90684086]]\n",
      "Cost at 420th loop = [[0.90208194]]\n",
      "Cost at 425th loop = [[0.89740914]]\n",
      "Cost at 430th loop = [[0.89282012]]\n",
      "Cost at 435th loop = [[0.88831263]]\n",
      "Cost at 440th loop = [[0.88388448]]\n",
      "Cost at 445th loop = [[0.87953357]]\n",
      "Cost at 450th loop = [[0.87525787]]\n",
      "Cost at 455th loop = [[0.87105541]]\n",
      "Cost at 460th loop = [[0.8669243]]\n",
      "Cost at 465th loop = [[0.86286269]]\n",
      "Cost at 470th loop = [[0.85886882]]\n",
      "Cost at 475th loop = [[0.85494098]]\n",
      "Cost at 480th loop = [[0.85107751]]\n",
      "Cost at 485th loop = [[0.8472768]]\n",
      "Cost at 490th loop = [[0.8435373]]\n",
      "Cost at 495th loop = [[0.83985752]]\n",
      "Cost at 500th loop = [[0.83623599]]\n",
      "Cost at 505th loop = [[0.83267132]]\n",
      "Cost at 510th loop = [[0.82916214]]\n",
      "Cost at 515th loop = [[0.82570714]]\n",
      "Cost at 520th loop = [[0.82230503]]\n",
      "Cost at 525th loop = [[0.81895457]]\n",
      "Cost at 530th loop = [[0.81565457]]\n",
      "Cost at 535th loop = [[0.81240385]]\n",
      "Cost at 540th loop = [[0.8092013]]\n",
      "Cost at 545th loop = [[0.80604582]]\n",
      "Cost at 550th loop = [[0.80293634]]\n",
      "Cost at 555th loop = [[0.79987184]]\n",
      "Cost at 560th loop = [[0.79685131]]\n",
      "Cost at 565th loop = [[0.79387378]]\n",
      "Cost at 570th loop = [[0.79093832]]\n",
      "Cost at 575th loop = [[0.788044]]\n",
      "Cost at 580th loop = [[0.78518995]]\n",
      "Cost at 585th loop = [[0.78237528]]\n",
      "Cost at 590th loop = [[0.77959917]]\n",
      "Cost at 595th loop = [[0.7768608]]\n",
      "Cost at 600th loop = [[0.77415938]]\n",
      "Cost at 605th loop = [[0.77149413]]\n",
      "Cost at 610th loop = [[0.76886431]]\n",
      "Cost at 615th loop = [[0.7662692]]\n",
      "Cost at 620th loop = [[0.76370807]]\n",
      "Cost at 625th loop = [[0.76118024]]\n",
      "Cost at 630th loop = [[0.75868504]]\n",
      "Cost at 635th loop = [[0.75622182]]\n",
      "Cost at 640th loop = [[0.75378994]]\n",
      "Cost at 645th loop = [[0.75138878]]\n",
      "Cost at 650th loop = [[0.74901774]]\n",
      "Cost at 655th loop = [[0.74667624]]\n",
      "Cost at 660th loop = [[0.74436369]]\n",
      "Cost at 665th loop = [[0.74207955]]\n",
      "Cost at 670th loop = [[0.73982328]]\n",
      "Cost at 675th loop = [[0.73759433]]\n",
      "Cost at 680th loop = [[0.7353922]]\n",
      "Cost at 685th loop = [[0.73321639]]\n",
      "Cost at 690th loop = [[0.7310664]]\n",
      "Cost at 695th loop = [[0.72894176]]\n",
      "Cost at 700th loop = [[0.726842]]\n",
      "Cost at 705th loop = [[0.72476667]]\n",
      "Cost at 710th loop = [[0.72271532]]\n",
      "Cost at 715th loop = [[0.72068752]]\n",
      "Cost at 720th loop = [[0.71868285]]\n",
      "Cost at 725th loop = [[0.7167009]]\n",
      "Cost at 730th loop = [[0.71474126]]\n",
      "Cost at 735th loop = [[0.71280354]]\n",
      "Cost at 740th loop = [[0.71088736]]\n",
      "Cost at 745th loop = [[0.70899235]]\n",
      "Cost at 750th loop = [[0.70711813]]\n",
      "Cost at 755th loop = [[0.70526435]]\n",
      "Cost at 760th loop = [[0.70343066]]\n",
      "Cost at 765th loop = [[0.70161672]]\n",
      "Cost at 770th loop = [[0.6998222]]\n",
      "Cost at 775th loop = [[0.69804677]]\n",
      "Cost at 780th loop = [[0.69629011]]\n",
      "Cost at 785th loop = [[0.69455191]]\n",
      "Cost at 790th loop = [[0.69283187]]\n",
      "Cost at 795th loop = [[0.69112969]]\n",
      "Cost at 800th loop = [[0.68944508]]\n",
      "Cost at 805th loop = [[0.68777775]]\n",
      "Cost at 810th loop = [[0.68612742]]\n",
      "Cost at 815th loop = [[0.68449383]]\n",
      "Cost at 820th loop = [[0.6828767]]\n",
      "Cost at 825th loop = [[0.68127577]]\n",
      "Cost at 830th loop = [[0.6796908]]\n",
      "Cost at 835th loop = [[0.67812152]]\n",
      "Cost at 840th loop = [[0.6765677]]\n",
      "Cost at 845th loop = [[0.6750291]]\n",
      "Cost at 850th loop = [[0.67350547]]\n",
      "Cost at 855th loop = [[0.67199659]]\n",
      "Cost at 860th loop = [[0.67050225]]\n",
      "Cost at 865th loop = [[0.6690222]]\n",
      "Cost at 870th loop = [[0.66755625]]\n",
      "Cost at 875th loop = [[0.66610417]]\n",
      "Cost at 880th loop = [[0.66466576]]\n",
      "Cost at 885th loop = [[0.66324083]]\n",
      "Cost at 890th loop = [[0.66182916]]\n",
      "Cost at 895th loop = [[0.66043056]]\n",
      "Cost at 900th loop = [[0.65904485]]\n",
      "Cost at 905th loop = [[0.65767183]]\n",
      "Cost at 910th loop = [[0.65631133]]\n",
      "Cost at 915th loop = [[0.65496316]]\n",
      "Cost at 920th loop = [[0.65362714]]\n",
      "Cost at 925th loop = [[0.6523031]]\n",
      "Cost at 930th loop = [[0.65099088]]\n",
      "Cost at 935th loop = [[0.6496903]]\n",
      "Cost at 940th loop = [[0.6484012]]\n",
      "Cost at 945th loop = [[0.64712343]]\n",
      "Cost at 950th loop = [[0.64585682]]\n",
      "Cost at 955th loop = [[0.64460122]]\n",
      "Cost at 960th loop = [[0.64335648]]\n",
      "Cost at 965th loop = [[0.64212244]]\n",
      "Cost at 970th loop = [[0.64089898]]\n",
      "Cost at 975th loop = [[0.63968593]]\n",
      "Cost at 980th loop = [[0.63848316]]\n",
      "Cost at 985th loop = [[0.63729054]]\n",
      "Cost at 990th loop = [[0.63610792]]\n",
      "Cost at 995th loop = [[0.63493517]]\n",
      "Cost at 1000th loop = [[0.63377217]]\n",
      "Cost at 1005th loop = [[0.63261878]]\n"
     ]
    }
   ],
   "source": [
    "res_W, res_b, costs = model(X, Y_hot, C, alpha=0.009, iterations=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = predict(X_test, Y_test_hot, res_W, res_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 5246   # 0-9999\n",
    "plt.imshow(test_images[image])\n",
    "print(f'The image no. is {test_labels[image]} and my Model predicts {predicted_labels[image]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A[:,0].max() == A[:,0]\n",
    "O = (np.max(A,axis=0) == A).T * np.array([0,1,2,3,4,5,6,7,8,9]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = np.sum(O,axis=1)\n",
    "F,train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{np.sum(F==train_labels)} images correctly labeled out of {train_labels.shape[0]} for Train Set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Accuracy : {100 - np.mean(np.abs(A- Y_hot))*100} on Train Set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Cost for training was {J}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "Z_test = np.dot(W.T, X_test) + b[:,:10000]\n",
    "A_test = softmax(Z_test)\n",
    "L_test = -np.sum(Y_test_hot*np.log(A_test), keepdims=True, axis=0)\n",
    "J_test = np.sum(L_test, keepdims=True, axis=1)*(1/m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O_test = (np.max(A_test,axis=0) == A_test).T * np.array([0,1,2,3,4,5,6,7,8,9]).T\n",
    "F_test = np.sum(O_test,axis=1)\n",
    "F_test, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{np.sum(F_test==test_labels)} images correctly labeled out of {test_labels.shape[0]} for Test Set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Accuracy : {100 - np.mean(np.abs(A_test- Y_test_hot))*100} on Test Set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Cost for training was {J_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 5246   # 0-9999\n",
    "plt.imshow(test_images[image])\n",
    "print(f'The image no. is {test_labels[image]} and my Model predicts {F_test[image]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([cost[0][0] for cost in costs], columns=['Cost'], index=np.arange(0,iterations,5)).to_csv('Cost.csv')\n",
    "pd.DataFrame(res_W).to_csv('res_W.csv', header=None,index=None)\n",
    "pd.DataFrame(res_b).to_csv('res_b.csv', header=None,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
